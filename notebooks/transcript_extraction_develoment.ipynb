{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e0b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Change to project root\n",
    "os.chdir(parent_dir)\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from services import UseCaseService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91faf4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f64ab0",
   "metadata": {},
   "source": [
    "# load example transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dffa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_path = \"test_data/transcripts/energy_workshop_transcript.txt\"\n",
    "\n",
    "with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "\n",
    "print(f\"Length: {len(transcript)} characters\")\n",
    "print(f\"\\nFirst 500 characters:\")\n",
    "print(transcript[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c36f0f",
   "metadata": {},
   "source": [
    "# Promt for extraction\n",
    "The plan is: a good promt to design a list of good promt to hand over one by one to the agent that I have tested and is able to add usecases to the database carefully (with checking and adding and everything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e208773",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_prompt = \"\"\"\n",
    "You are an expert at extracting use cases from workshop transcripts.\n",
    "\n",
    "Your task is to read the transcript and create a natural language prompt for EACH use case \n",
    "that can be executed by an AI agent to create the use case in a database.\n",
    "\n",
    "For each use case mentioned in the transcript, create a prompt following this template:\n",
    "\"Create a use case called '[TITLE]' for company '[COMPANY]' in the '[INDUSTRY]' sector. Description: [DETAILED DESCRIPTION]. Expected benefit: [SPECIFIC BENEFITS]. Contributors: [NAME (ROLE), NAME (ROLE)]\"\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Extract ALL use cases discussed in the transcript (there may be multiple)\n",
    "2. For each use case, identify:\n",
    "   - A clear, concise title\n",
    "   - The company name (exactly as mentioned)\n",
    "   - The industry/sector\n",
    "   - A detailed description of what the use case does\n",
    "   - The expected benefits (include metrics/percentages when mentioned)\n",
    "   - All people who contributed ideas (with their roles)\n",
    "\n",
    "3. Return ONLY a JSON array of prompt strings\n",
    "4. Each prompt should be a complete, standalone instruction\n",
    "5. Use exact quotes for percentages and metrics when available\n",
    "\n",
    "EXAMPLE OUTPUT FORMAT:\n",
    "[\n",
    "  \"Create a use case called 'Smart Grid Optimization' for company 'E.ON' in the 'Energy' sector. Description: Machine learning algorithms to optimize energy distribution in real-time based on consumption patterns and renewable energy availability. Expected benefit: Reduce energy waste by 15-20%, improve grid stability, better integration of renewable sources. Contributors: Lisa Müller (Innovation Manager), Thomas Klein (Data Science Lead)\",\n",
    "  \"Create a use case called 'Predictive Maintenance for Wind Turbines' for company 'E.ON' in the 'Energy' sector. Description: IoT sensors combined with AI to predict maintenance needs before failures occur, reducing downtime. Expected benefit: 30% reduction in unplanned downtime, 20% longer equipment lifetime, lower maintenance costs. Contributors: Thomas Klein (Data Science Lead), Lisa Müller (Innovation Manager)\"\n",
    "]\n",
    "\n",
    "CRITICAL: Return ONLY the JSON array, no other text, no markdown formatting, no preamble.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838dff2",
   "metadata": {},
   "source": [
    "# function to let the LLM run to create promts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3119fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prompts_from_transcript(transcript_text: str, verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Extract use case prompts from a workshop transcript.\n",
    "    \n",
    "    Args:\n",
    "        transcript_text: The full transcript text\n",
    "        verbose: Whether to print progress\n",
    "        \n",
    "    Returns:\n",
    "        list: List of prompt strings for the agent\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"EXTRACTING USE CASE PROMPTS FROM TRANSCRIPT\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # Call LLM with extraction prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"anthropic/claude-3.5-sonnet\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": extraction_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Extract use case prompts from this transcript:\\n\\n{transcript_text}\"}\n",
    "        ],\n",
    "        max_tokens=3000,\n",
    "        temperature=0.3  # Lower temp for consistent extraction\n",
    "    )\n",
    "    \n",
    "    result = response.choices[0].message.content\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nLLM Response:\")\n",
    "        print(result[:300] + \"...\" if len(result) > 300 else result)\n",
    "    \n",
    "    # Parse JSON\n",
    "    try:\n",
    "        # Clean markdown formatting if present\n",
    "        if \"```json\" in result:\n",
    "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in result:\n",
    "            result = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "        \n",
    "        prompts = json.loads(result)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nSuccessfully extracted {len(prompts)} use case prompt(s)\")\n",
    "            print(\"\\nExtracted prompts:\")\n",
    "            for i, prompt in enumerate(prompts, 1):\n",
    "                print(f\"\\n{i}. {prompt[:100]}...\")\n",
    "        \n",
    "        return prompts\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"\\nFailed to parse JSON: {e}\")\n",
    "        print(f\"Raw response:\\n{result}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab1f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test extraction on energy transcript\n",
    "print(\"\\nTesting extraction on energy workshop transcript...\")\n",
    "prompts = extract_prompts_from_transcript(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39fc551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d12ade2a",
   "metadata": {},
   "source": [
    "# Test Complete workflow :o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85efe21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import run_agent\n",
    "\n",
    "def process_transcript(transcript_text: str, verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Complete workflow: Extract prompts from transcript and create all use cases.\n",
    "    \n",
    "    Args:\n",
    "        transcript_text: The workshop transcript\n",
    "        verbose: Whether to print detailed progress\n",
    "        \n",
    "    Returns:\n",
    "        dict: Summary of results\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"TRANSCRIPT PROCESSING WORKFLOW\")\n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    # Step 1: Extract prompts\n",
    "    prompts = extract_prompts_from_transcript(transcript_text, verbose=verbose)\n",
    "    \n",
    "    if not prompts:\n",
    "        print(\"\\nNo prompts extracted. Stopping.\")\n",
    "        return {\"success\": False, \"prompts_extracted\": 0, \"use_cases_created\": 0}\n",
    "    \n",
    "    # Step 2: Process each prompt with the agent\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"CREATING {len(prompts)} USE CASE(S) VIA AGENT\")\n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    results = []\n",
    "    for i, prompt in enumerate(prompts, 1):\n",
    "        if verbose:\n",
    "            print(f\"\\n{'─'*80}\")\n",
    "            print(f\"USE CASE {i}/{len(prompts)}\")\n",
    "            print(f\"{'─'*80}\")\n",
    "            print(f\"Prompt: {prompt[:150]}...\")\n",
    "            print()\n",
    "        \n",
    "        try:\n",
    "            # Feed prompt to agent\n",
    "            response = run_agent(prompt, verbose=verbose)\n",
    "            results.append({\"success\": True, \"prompt\": prompt, \"response\": response})\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nUse case {i} created successfully\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"\\nError creating use case {i}: {e}\")\n",
    "            results.append({\"success\": False, \"prompt\": prompt, \"error\": str(e)})\n",
    "    \n",
    "    # Summary\n",
    "    successful = sum(1 for r in results if r[\"success\"])\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"TRANSCRIPT PROCESSING COMPLETE\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Prompts extracted: {len(prompts)}\")\n",
    "        print(f\"Use cases created: {successful}/{len(prompts)}\")\n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"prompts_extracted\": len(prompts),\n",
    "        \"use_cases_created\": successful,\n",
    "        \"results\": results\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the energy transcript end-to-end\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FULL TRANSCRIPT PROCESSING TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = process_transcript(transcript, verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Extracted {summary['prompts_extracted']} use case prompts\")\n",
    "print(f\"Successfully created {summary['use_cases_created']} use cases\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_data/transcripts/manufacturing_workshop_transcript.txt\", 'r', encoding='utf-8') as f:\n",
    "    manufacturing_transcript = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55898eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = process_transcript(manufacturing_transcript, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load healthcare transcript\n",
    "with open(\"test_data/transcripts/healthcare_workshop_transcript.txt\", 'r', encoding='utf-8') as f:\n",
    "    healthcare_transcript = f.read()\n",
    "\n",
    "# Process it\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING HEALTHCARE TRANSCRIPT\")\n",
    "print(\"=\"*80)\n",
    "summary = process_transcript(healthcare_transcript, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b500de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
